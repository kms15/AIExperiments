{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic experiments with GPU programming in julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is roughly based on the CUArrays package introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Test\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise product experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test performance of a simple (large) vector Hadamard product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=2^28\n",
    "x = fill(2.0f0, N)\n",
    "y = fill(3.0f0, N)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single threaded on a CPU, using broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.00 GiB\n",
       "  allocs estimate:  4\n",
       "  --------------\n",
       "  minimum time:     527.503 ms (0.03% GC)\n",
       "  median time:      555.744 ms (4.61% GC)\n",
       "  mean time:        556.384 ms (5.06% GC)\n",
       "  maximum time:     591.918 ms (11.05% GC)\n",
       "  --------------\n",
       "  samples:          9\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test all(x .* y .== 6.0f0)\n",
    "@benchmark z = x .* y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single threaded on a CPU, using loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.00 GiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     527.501 ms (0.03% GC)\n",
       "  median time:      553.928 ms (4.61% GC)\n",
       "  mean time:        555.760 ms (5.11% GC)\n",
       "  maximum time:     595.746 ms (11.16% GC)\n",
       "  --------------\n",
       "  samples:          9\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function serial_mul(x, y)\n",
    "    z = similar(x)\n",
    "    for i in eachindex(x,y,z)\n",
    "        @inbounds z[i] = x[i] * y[i]\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "\n",
    "@test all(serial_mul(x, y) .== 6.0f0)\n",
    "@benchmark z = serial_mul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi threaded on a CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.00 GiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     88.876 ms (12.38% GC)\n",
       "  median time:      122.169 ms (35.71% GC)\n",
       "  mean time:        125.183 ms (33.65% GC)\n",
       "  maximum time:     184.174 ms (25.04% GC)\n",
       "  --------------\n",
       "  samples:          40\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function threaded_mul(x, y)\n",
    "    z = similar(x)\n",
    "    Threads.@threads for i in eachindex(x,y,z)\n",
    "        @inbounds z[i] = x[i] * y[i]\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "\n",
    "@test all(threaded_mul(x, y) .== 6.0f0)\n",
    "@benchmark z = threaded_mul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU with broadcasting (multithreaded and grided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CuArrays\n",
    "\n",
    "x_gpu = cufill(2.0f0, N)\n",
    "y_gpu = cufill(3.0f0, N)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.27 KiB\n",
       "  allocs estimate:  62\n",
       "  --------------\n",
       "  minimum time:     7.425 ms (0.00% GC)\n",
       "  median time:      8.576 ms (0.00% GC)\n",
       "  mean time:        48.540 ms (39.45% GC)\n",
       "  maximum time:     292.942 ms (51.80% GC)\n",
       "  --------------\n",
       "  samples:          103\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function broadcast_gpu_mul(x, y)\n",
    "    CuArrays.@sync z = x .* y\n",
    "    return z\n",
    "end\n",
    "\n",
    "@test all(broadcast_gpu_mul(x_gpu, y_gpu) .== 6.0f0)\n",
    "@benchmark z_gpu = broadcast_gpu_mul(x_gpu, y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single threaded on GPU (custom kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDAnative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  912 bytes\n",
       "  allocs estimate:  34\n",
       "  --------------\n",
       "  minimum time:     11.969 s (0.00% GC)\n",
       "  median time:      11.969 s (0.00% GC)\n",
       "  mean time:        11.969 s (0.00% GC)\n",
       "  maximum time:     11.969 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function serial_gpu_mul!(z, x, y)\n",
    "    for i in 1:length(x)\n",
    "        @inbounds z[i] = x[i] * y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function serial_gpu_mul(x, y)\n",
    "    z = similar(x)\n",
    "    CuArrays.@sync begin\n",
    "        @cuda serial_gpu_mul!(z, x, y)\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "\n",
    "@test all(serial_gpu_mul(x_gpu, y_gpu) .== 6.0f0)\n",
    "@benchmark z_gpu = serial_gpu_mul(x_gpu, y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi threaded on GPU, single SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  944 bytes\n",
       "  allocs estimate:  36\n",
       "  --------------\n",
       "  minimum time:     87.583 ms (0.00% GC)\n",
       "  median time:      89.332 ms (0.00% GC)\n",
       "  mean time:        128.703 ms (14.55% GC)\n",
       "  maximum time:     381.845 ms (40.29% GC)\n",
       "  --------------\n",
       "  samples:          39\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function threaded_gpu_mul!(z, x, y)\n",
    "    index = threadIdx().x\n",
    "    stride = blockDim().x\n",
    "    \n",
    "    for i in index:stride:length(x)\n",
    "        @inbounds z[i] = x[i] * y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function threaded_gpu_mul(x, y)\n",
    "    z = similar(x)\n",
    "    CuArrays.@sync begin\n",
    "        @cuda threads=1024 threaded_gpu_mul!(z, x, y)\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "\n",
    "@test all(threaded_gpu_mul(x_gpu, y_gpu) .== 6.0f0)\n",
    "@benchmark z_gpu = threaded_gpu_mul(x_gpu, y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreaded and grided on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grided_gpu_mul (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function grided_gpu_mul!(z, x, y)\n",
    "    index = threadIdx().x + (blockIdx().x - 1)*blockDim().x\n",
    "    stride = blockDim().x * gridDim().x\n",
    "    \n",
    "    for i in index:stride:length(x)\n",
    "        @inbounds z[i] = x[i] * y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function grided_gpu_mul(x, y)\n",
    "    z = similar(x)\n",
    "    numthreads = 64\n",
    "    numblocks = ceil(Int, length(x)/numthreads)\n",
    "    CuArrays.@sync begin\n",
    "        @cuda threads=numthreads blocks=numblocks grided_gpu_mul!(z, x, y)\n",
    "    end\n",
    "    return z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  960 bytes\n",
       "  allocs estimate:  36\n",
       "  --------------\n",
       "  minimum time:     7.323 ms (0.00% GC)\n",
       "  median time:      8.175 ms (0.00% GC)\n",
       "  mean time:        47.277 ms (37.82% GC)\n",
       "  maximum time:     259.889 ms (44.75% GC)\n",
       "  --------------\n",
       "  samples:          111\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test all(grided_gpu_mul(x_gpu, y_gpu) .== 6.0f0)\n",
    "@benchmark z_gpu = grided_gpu_mul(x_gpu, y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numgpus = 10\n",
    "n = ceil(Int, N/numgpus)\n",
    "\n",
    "function devicefill(dev, value, shape)\n",
    "    device!(dev) do\n",
    "        return cufill(value, shape)\n",
    "    end\n",
    "end\n",
    "\n",
    "x_gpus = [devicefill(dev, 2.0f0, n) for dev in 0:(numgpus-1)]\n",
    "y_gpus = [devicefill(dev, 3.0f0, n) for dev in 0:(numgpus-1)]\n",
    "z_gpus = [devicefill(dev, 2.0f0, n) for dev in 0:(numgpus-1)]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.001097 seconds (252 CPU allocations: 6.781 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  6.78 KiB\n",
       "  allocs estimate:  252\n",
       "  --------------\n",
       "  minimum time:     896.695 μs (0.00% GC)\n",
       "  median time:      991.684 μs (0.00% GC)\n",
       "  mean time:        1.042 ms (0.44% GC)\n",
       "  maximum time:     35.347 ms (61.21% GC)\n",
       "  --------------\n",
       "  samples:          4742\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function multi_gpu_mul!(z_gpus, x_gpus, y_gpus)\n",
    "    function kernel!(z, x, y)\n",
    "        index = threadIdx().x + (blockIdx().x - 1)*blockDim().x\n",
    "        stride = blockDim().x * gridDim().x\n",
    "    \n",
    "        for i in index:stride:length(x)\n",
    "            @inbounds z[i] = x[i] * y[i]\n",
    "        end\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    # launch each kernel\n",
    "    for i in 1:numgpus\n",
    "        device!(i-1) do\n",
    "            numthreads = 128\n",
    "            numblocks = ceil(Int, length(x_gpus[i])/numthreads)\n",
    "            @cuda threads=numthreads blocks=numblocks kernel!(z_gpus[i], x_gpus[i], y_gpus[i])\n",
    "        end\n",
    "    end\n",
    "    # resynchronize each device (for timing purposes)\n",
    "    for i in 1:numgpus\n",
    "        device!(i-1) do\n",
    "            CuArrays.@sync 1\n",
    "        end\n",
    "    end\n",
    "    return z_gpus\n",
    "end\n",
    "\n",
    "@test all(vcat((Array.(multi_gpu_mul!(z_gpus, x_gpus, y_gpus)))...) .== 6.0f0)\n",
    "CuArrays.@time multi_gpu_mul!(z_gpus, x_gpus, y_gpus)\n",
    "@benchmark multi_gpu_mul!(z_gpus, x_gpus, y_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor contraction experiment\n",
    "\n",
    "Calculate a simple tensor contraction, i.e.\n",
    "\n",
    "$$z_{i,j,k} = \\sum_{l} x_{l,i,j} y_{l, k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "rng = MersenneTwister(1842)\n",
    "\n",
    "t1 = randn(rng, Float32, (200, 600, 300))\n",
    "t2 = randn(rng, Float32, (200, 300))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of single precision floating point operations involved in this calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21546000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numspflops = *(size(t1)[2:end]..., size(t2)[2:end]...) * (2 * size(t1)[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU single threaded approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPS (SP): 2.275835175870624\n",
      "trial = Trial(9.467 s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     9.467 s (0.00% GC)\n",
       "  median time:      9.467 s (0.00% GC)\n",
       "  mean time:        9.467 s (0.00% GC)\n",
       "  maximum time:     9.467 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = Array{Float32}(undef, size(t1)[2], size(t1)[3], size(t2)[2])\n",
    "\n",
    "function calc_t3_loop!(t3, t1, t2)\n",
    "    for k in 1:size(t3)[3]\n",
    "        for j in 1:size(t3)[2]\n",
    "            for i in 1:size(t3)[1]\n",
    "                @inbounds t3[i,j,k] = t1[1,i,j] * t2[1,k]\n",
    "\n",
    "                for l in 2:size(t1)[1]\n",
    "                    @inbounds t3[i,j,k] += t1[l,i,j] * t2[l,k]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "trial = @benchmark calc_t3_loop!($t3, $t1, $t2)\n",
    "print(\"GFLOPS (SP): $(numspflops/median(trial).time)\\n\")\n",
    "@show trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU multi-threaded approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPS (SP): 55.97422159779707\n",
      "trial = Trial(319.334 ms)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  48 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     319.334 ms (0.00% GC)\n",
       "  median time:      384.927 ms (0.00% GC)\n",
       "  mean time:        367.775 ms (0.00% GC)\n",
       "  maximum time:     401.112 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          14\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3_2 = Array{Float32}(undef, size(t1)[2], size(t1)[3], size(t2)[2])\n",
    "\n",
    "function calc_t3_loop_threaded!(t3, t1, t2)\n",
    "    Threads.@threads for k in 1:size(t3)[3]\n",
    "        for j in 1:size(t3)[2]\n",
    "            for i in 1:size(t3)[1]\n",
    "                @inbounds t3[i,j,k] = t1[1,i,j] * t2[1,k]\n",
    "\n",
    "                for l in 2:size(t1)[1]\n",
    "                    @inbounds t3[i,j,k] += t1[l,i,j] * t2[l,k]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "trial = @benchmark calc_t3_loop_threaded!($t3_2, $t1, $t2)\n",
    "@test maximum(abs.(t3_2 - t3)) .< 1e-5 # confirm results match the single threaded results\n",
    "print(\"GFLOPS (SP): $(numspflops/median(trial).time)\\n\")\n",
    "@show trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPS (SP): 199.42954228133993\n",
      "trial = Trial(107.263 ms)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  528 bytes\n",
       "  allocs estimate:  15\n",
       "  --------------\n",
       "  minimum time:     107.263 ms (0.00% GC)\n",
       "  median time:      108.038 ms (0.00% GC)\n",
       "  mean time:        107.975 ms (0.00% GC)\n",
       "  maximum time:     108.270 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          47\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1cu = CuArray(t1)\n",
    "t2cu = CuArray(t2)\n",
    "t3cu = CuArray{Float32}(undef, size(t1)[2], size(t1)[3], size(t2)[2])\n",
    "\n",
    "function calc_t3_gpu!(t3, t1, t2)\n",
    "    function kernel!(t3, t1, t2)\n",
    "        xindex = threadIdx().x + (blockIdx().x - 1)*blockDim().x\n",
    "        yindex = threadIdx().y + (blockIdx().y - 1)*blockDim().y\n",
    "        zindex = threadIdx().z + (blockIdx().z - 1)*blockDim().z\n",
    "        \n",
    "        xstride = blockDim().x * gridDim().x\n",
    "        ystride = blockDim().y * gridDim().y\n",
    "        zstride = blockDim().z * gridDim().z\n",
    "    \n",
    "        for k in zindex:zstride:size(t3)[3]\n",
    "            for j in yindex:ystride:size(t3)[2]\n",
    "                for i in xindex:xstride:size(t3)[1]\n",
    "                    @inbounds t3[i,j,k] = t1[1,i,j] * t2[1,k]\n",
    "                    \n",
    "                    for l in 2:size(t1)[1]\n",
    "                        @inbounds t3[i,j,k] += t1[l,i,j] * t2[l,k]\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    numthreads = (4,4,4)\n",
    "    numblocks = map(x -> ceil(Int, x), (size(t3) ./ numthreads))\n",
    "    CuArrays.@sync begin\n",
    "        @cuda threads=numthreads blocks=numblocks kernel!(t3, t1, t2)\n",
    "    end\n",
    "end\n",
    "\n",
    "trial = @benchmark calc_t3_gpu!($t3cu, $t1cu, $t2cu)\n",
    "@test maximum(abs.(Array(t3cu) - t3)) < 1e-4 # confirm results match the single threaded results\n",
    "print(\"GFLOPS (SP): $(numspflops/median(trial).time)\\n\")\n",
    "@show trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "function allocgpuarrays(t1, t2, numgpus)\n",
    "    t1s = Array{CuArray{Float32,3}}(undef,0)\n",
    "    t2s = Array{CuArray{Float32,2}}(undef,0)\n",
    "    t3s = Array{CuArray{Float32,3}}(undef,0)\n",
    "    slabsize = ceil(Int, size(t1)[2]/numgpus)\n",
    "    for i in 1:numgpus\n",
    "        indexstart = (i-1)*slabsize + 1\n",
    "        indexend = min(i*slabsize, size(t1)[2])\n",
    "        device!(i-1) do\n",
    "            push!(t1s, CuArray(t1[:,indexstart:indexend,:]))\n",
    "            push!(t2s, CuArray(t2))\n",
    "            push!(t3s, CuArray{Float32}(undef, indexend - indexstart + 1, size(t1)[3], size(t2)[2]))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return t1s, t2s, t3s\n",
    "end\n",
    "\n",
    "t1s, t2s, t3s = allocgpuarrays(t1, t2, numgpus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_t3_gpu_nosync!(t3, t1, t2)\n",
    "    function kernel!(t3, t1, t2)\n",
    "        xindex = threadIdx().x + (blockIdx().x - 1)*blockDim().x\n",
    "        yindex = threadIdx().y + (blockIdx().y - 1)*blockDim().y\n",
    "        zindex = threadIdx().z + (blockIdx().z - 1)*blockDim().z\n",
    "        \n",
    "        xstride = blockDim().x * gridDim().x\n",
    "        ystride = blockDim().y * gridDim().y\n",
    "        zstride = blockDim().z * gridDim().z\n",
    "    \n",
    "        for k in zindex:zstride:size(t3)[3]\n",
    "            for j in yindex:ystride:size(t3)[2]\n",
    "                for i in xindex:xstride:size(t3)[1]\n",
    "                    @inbounds t3[i,j,k] = t1[1,i,j] * t2[1,k]\n",
    "                    \n",
    "                    for l in 2:size(t1)[1]\n",
    "                        @inbounds t3[i,j,k] += t1[l,i,j] * t2[l,k]\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    numthreads = (8,4,4)\n",
    "    numblocks = map(x -> ceil(Int, x), (size(t3) ./ numthreads))\n",
    "    @cuda threads=numthreads blocks=numblocks kernel!(t3, t1, t2)\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPS (SP): 1724.17518311259\n",
      "trial = Trial(12.366 ms)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.56 KiB\n",
       "  allocs estimate:  262\n",
       "  --------------\n",
       "  minimum time:     12.366 ms (0.00% GC)\n",
       "  median time:      12.496 ms (0.00% GC)\n",
       "  mean time:        12.658 ms (0.00% GC)\n",
       "  maximum time:     15.244 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          395\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_t3_gpus!(t3s, t1s, t2s)\n",
    "    for i in 1:numgpus\n",
    "        device!(i-1) do\n",
    "            calc_t3_gpu_nosync!(t3s[i], t1s[i], t2s[i])\n",
    "        end\n",
    "    end\n",
    "    # resynchronize each device (for timing purposes)\n",
    "    for i in 1:numgpus\n",
    "        device!(i-1) do\n",
    "            CuArrays.@sync 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "trial = @benchmark calc_t3_gpus!($t3s, $t1s, $t2s)\n",
    "@test maximum(abs.(vcat(map(Array,t3s)...) - t3)) < 1e-4 # confirm results match the single threaded results\n",
    "print(\"GFLOPS (SP): $(numspflops/median(trial).time)\\n\")\n",
    "@show trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (44 threads) 1.0.3",
   "language": "julia",
   "name": "julia-(44-threads)-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
